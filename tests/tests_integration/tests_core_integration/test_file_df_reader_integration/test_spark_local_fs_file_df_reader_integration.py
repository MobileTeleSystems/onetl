"""Integration tests for FileDFReader, specific for SparkLocalFS.

Test only that options generated by both FileDFReader and FileDFReader.Options are passed to Spark,
and behavior is the same as described in documentation.
Also test internal validation of values passed to .run() method.

Do not test all possible options and combinations, we are not testing Spark here.
"""

import pytest

from onetl.file import FileDFReader
from onetl.file.format import CSV


# SparkS3 does not support empty directories concept, running this tests only with SparkLocalFS
def test_file_df_reader_run_with_empty_source_path(local_fs_file_df_connection_with_path, file_df_schema):
    file_df_connection, source_path = local_fs_file_df_connection_with_path

    reader = FileDFReader(
        connection=file_df_connection,
        format=CSV(),
        source_path=source_path,
        df_schema=file_df_schema,
    )

    read_df = reader.run()
    assert not read_df.count()
    assert read_df.schema == file_df_schema


def test_file_df_reader_run_no_files_and_no_schema(
    local_fs_file_df_connection_with_path,
):
    file_df_connection, source_path = local_fs_file_df_connection_with_path
    reader = FileDFReader(
        connection=file_df_connection,
        format=CSV(),
        source_path=source_path,
    )

    msg = "Unable to infer schema for CSV. It must be specified manually"
    with pytest.raises(Exception, match=msg):
        reader.run()

    with pytest.raises(Exception, match=msg):
        reader.run([])


<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      
      <link rel="icon" href="../assets/images/icon.svg">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>onETL - onETL Docs</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../assets/stylesheets/autodoc_pydantic.css">
    
      <link rel="stylesheet" href="../assets/mkdocs_puml/puml.css">
    
      <link rel="stylesheet" href="../assets/mkdocs_puml/interaction.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#onetl" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="onETL Docs" class="md-header__button md-logo" aria-label="onETL Docs" data-md-component="logo">
      
  <img src="../assets/images/logo.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            onETL Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              onETL
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
      <div class="md-header__option">
  <div class="md-select">
    
    <button class="md-header__button md-icon" aria-label="Select language">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"/></svg>
    </button>
    <div class="md-select__inner">
      <ul class="md-select__list">
        
          <li class="md-select__item">
            <a href="/en/" hreflang="en" class="md-select__link">
              English
            </a>
          </li>
        
          <li class="md-select__item">
            <a href="/ru/" hreflang="ru" class="md-select__link">
              Русский
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</div>
    
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="onETL Docs" class="md-nav__button md-logo" aria-label="onETL Docs" data-md-component="logo">
      
  <img src="../assets/images/logo.svg" alt="logo">

    </a>
    onETL Docs
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../concepts" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Concepts
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quickstart
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../logging" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Logging
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../security" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Security
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../contributing" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Contributing Guide
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../changelog/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    changelog
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_6" id="__nav_6_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            changelog
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.13.4" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.13.4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.13.3" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.13.3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.13.1" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.13.1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.13.0" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.13.0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.12.5" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.12.5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.12.4" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.12.4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.12.3" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.12.3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.12.2" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.12.2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.12.1" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.12.1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.12.0" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.12.0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.11.2" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.11.2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.11.1" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.11.1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.11.0" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.11.0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.10.2" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.10.2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.10.1" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.10.1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.10.0" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.10.0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.9.5" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.9.5
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.9.4" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.9.4
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.9.3" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.9.3
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.9.2" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.9.2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.9.1" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.9.1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.9.0" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.9.0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.8.1" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.8.1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.8.0" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.8.0
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.7.2" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.7.2
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.7.1" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.7.1
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../changelog/0.7.0" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0.7.0
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../db_/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    DB
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_7" id="__nav_7_label" tabindex="0">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            DB
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../db_/reader" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DBReader
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../db_/writer" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    DBWriter
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#what-is-onetl" class="md-nav__link">
    <span class="md-ellipsis">
      What is onETL?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#goals" class="md-nav__link">
    <span class="md-ellipsis">
      Goals
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#non-goals" class="md-nav__link">
    <span class="md-ellipsis">
      Non-goals
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#requirements" class="md-nav__link">
    <span class="md-ellipsis">
      Requirements
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#supported-storages" class="md-nav__link">
    <span class="md-ellipsis">
      Supported storages
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#documentation" class="md-nav__link">
    <span class="md-ellipsis">
      Documentation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#how-to-install" class="md-nav__link">
    <span class="md-ellipsis">
      How to install
    </span>
  </a>
  
    <nav class="md-nav" aria-label="How to install">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#minimal-installation" class="md-nav__link">
    <span class="md-ellipsis">
      Minimal installation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with-db-and-filedf-connections" class="md-nav__link">
    <span class="md-ellipsis">
      With DB and FileDF connections
    </span>
  </a>
  
    <nav class="md-nav" aria-label="With DB and FileDF connections">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#compatibility-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Compatibility matrix
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with-file-connections" class="md-nav__link">
    <span class="md-ellipsis">
      With File connections
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#with-kerberos-support" class="md-nav__link">
    <span class="md-ellipsis">
      With Kerberos support
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#full-bundle" class="md-nav__link">
    <span class="md-ellipsis">
      Full bundle
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#quick-start" class="md-nav__link">
    <span class="md-ellipsis">
      Quick start
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Quick start">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mssql-hive" class="md-nav__link">
    <span class="md-ellipsis">
      MSSQL → Hive
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sftp-hdfs" class="md-nav__link">
    <span class="md-ellipsis">
      SFTP → HDFS
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#s3-postgres" class="md-nav__link">
    <span class="md-ellipsis">
      S3 → Postgres
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="onetl">onETL<a class="headerlink" href="#onetl" title="Permanent link">&para;</a></h1>
<p><a href="https://github.com/MobileTeleSystems/onetl"><img alt="Repo status - Active" src="https://www.repostatus.org/badges/latest/active.svg" /></a>
<a href="https://pypi.org/project/onetl/"><img alt="PyPI - Latest Release" src="https://img.shields.io/pypi/v/onetl" /></a>
<a href="https://github.com/MobileTeleSystems/onetl/blob/develop/LICENSE.txt"><img alt="PyPI - License" src="https://img.shields.io/pypi/l/onetl.svg" /></a>
<a href="https://pypi.org/project/onetl/"><img alt="PyPI - Python Version" src="https://img.shields.io/pypi/pyversions/onetl.svg" /></a>
<a href="https://pypi.org/project/onetl/"><img alt="PyPI - Downloads" src="https://img.shields.io/pypi/dm/onetl" /></a></p>
<p><a href="https://onetl.readthedocs.io/"><img alt="Documentation - ReadTheDocs" src="https://readthedocs.org/projects/onetl/badge/?version=stable" /></a>
<a href="https://github.com/MobileTeleSystems/onetl/actions"><img alt="Github Actions - latest CI build status" src="https://github.com/MobileTeleSystems/onetl/workflows/Tests/badge.svg" /></a>
<a href="https://results.pre-commit.ci/latest/github/MobileTeleSystems/onetl/develop"><img alt="pre-commit.ci Status" src="https://results.pre-commit.ci/badge/github/MobileTeleSystems/onetl/develop.svg" /></a></p>
<!-- {-{ test_cov_badge }-} -->

<p><a href="https://github.com/MobileTeleSystems/onetl"><img alt="onETL logo" src="../en/assets/images/logo_wide.svg" /></a></p>
<h2 id="what-is-onetl">What is onETL?<a class="headerlink" href="#what-is-onetl" title="Permanent link">&para;</a></h2>
<p>Python ETL/ELT library powered by <a href="https://spark.apache.org/">Apache Spark</a> &amp; other open-source tools.</p>
<h2 id="goals">Goals<a class="headerlink" href="#goals" title="Permanent link">&para;</a></h2>
<ul>
<li>Provide unified classes to extract data from (<strong>E</strong>) &amp; load data to (<strong>L</strong>) various stores.</li>
<li>Provides <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.html">Spark DataFrame API</a> for performing transformations (<strong>T</strong>) in terms of <em>ETL</em>.</li>
<li>Provide direct assess to database, allowing to execute SQL queries, as well as DDL, DML, and call functions/procedures. This can be used for building up <em>ELT</em> pipelines.</li>
<li>Support different <a href="../strategy/">read strategies</a> for incremental and batch data fetching.</li>
<li>Provide <a href="../hooks/">hooks</a> &amp; <a href="../plugins">plugins</a> mechanism for altering behavior of internal classes.</li>
</ul>
<h2 id="non-goals">Non-goals<a class="headerlink" href="#non-goals" title="Permanent link">&para;</a></h2>
<ul>
<li>onETL is not a Spark replacement. It just provides additional functionality that Spark does not have, and improves UX for end users.</li>
<li>onETL is not a framework, as it does not have requirements to project structure, naming, the way of running ETL/ELT processes, configuration, etc. All of that should be implemented in some other tool.</li>
<li>onETL is deliberately developed without any integration with scheduling software like Apache Airflow. All integrations should be implemented as separated tools.</li>
<li>Only batch operations, no streaming. For streaming prefer <a href="https://flink.apache.org/">Apache Flink</a>.</li>
</ul>
<h2 id="requirements">Requirements<a class="headerlink" href="#requirements" title="Permanent link">&para;</a></h2>
<ul>
<li><strong>Python</strong> 3.7 - 3.13</li>
<li>PySpark 2.3.x - 3.5.x (depends on used connector)</li>
<li>Java 8+ (required by Spark, see below)</li>
<li>Kerberos libs &amp; GCC (required by <code>Hive</code>, <code>HDFS</code> and <code>SparkHDFS</code> connectors)</li>
</ul>
<h2 id="supported-storages">Supported storages<a class="headerlink" href="#supported-storages" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>Type</th>
<th>Storage</th>
<th>Powered by</th>
</tr>
</thead>
<tbody>
<tr>
<td rowspan="5">Database</td>
<td>Clickhouse<br/>MSSQL<br/>MySQL<br/>Postgres<br/>Oracle<br/>Teradata</td>
<td><br/><br/>Apache Spark <a href="https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html">JDBC Data Source</a></td>
</tr>
<tr>
<td>Hive</td>
<td>Apache Spark <a href="https://spark.apache.org/docs/latest/sql-data-sources-hive-tables.html">Hive integration</a></td>
<td></td>
</tr>
<tr>
<td>Kafka</td>
<td>Apache Spark <a href="https://spark.apache.org/docs/latest/structured-streaming-kafka-integration.html">Kafka integration</a></td>
<td></td>
</tr>
<tr>
<td>Greenplum</td>
<td>VMware <a href="https://docs.vmware.com/en/VMware-Greenplum-Connector-for-Apache-Spark/index.html">Greenplum Spark connector</a></td>
<td></td>
</tr>
<tr>
<td>MongoDB</td>
<td><a href="https://www.mongodb.com/docs/spark-connector/current">MongoDB Spark connector</a></td>
<td></td>
</tr>
<tr>
<td rowspan="6">File</td>
<td>HDFS</td>
<td><a href="https://pypi.org/project/hdfs/">HDFS Python client</a></td>
</tr>
<tr>
<td>S3</td>
<td><a href="https://pypi.org/project/minio/">minio-py client</a></td>
<td></td>
</tr>
<tr>
<td>SFTP</td>
<td><a href="https://pypi.org/project/paramiko/">Paramiko library</a></td>
<td></td>
</tr>
<tr>
<td>FTP<br/>FTPS</td>
<td><a href="https://pypi.org/project/ftputil/">FTPUtil library</a></td>
<td></td>
</tr>
<tr>
<td>WebDAV</td>
<td><a href="https://pypi.org/project/webdavclient3/">WebdavClient3 library</a></td>
<td></td>
</tr>
<tr>
<td>Samba</td>
<td><a href="https://pypi.org/project/pysmb/">pysmb library</a></td>
<td></td>
</tr>
<tr>
<td rowspan="2">Files as DataFrame</td>
<td>SparkLocalFS<br/>SparkHDFS</td>
<td>Apache Spark <a href="https://spark.apache.org/docs/latest/sql-data-sources-generic-options.html">File Data Source</a></td>
</tr>
<tr>
<td>SparkS3</td>
<td><a href="https://hadoop.apache.org/docs/current3/hadoop-aws/tools/hadoop-aws/index.html">Hadoop AWS</a> library</td>
<td></td>
</tr>
</tbody>
</table>
<!-- (documentation)= -->

<h2 id="documentation">Documentation<a class="headerlink" href="#documentation" title="Permanent link">&para;</a></h2>
<p>See at <a href="https://onetl.readthedocs.io/en/latest/">ReadTheDocs</a></p>
<h2 id="how-to-install">How to install<a class="headerlink" href="#how-to-install" title="Permanent link">&para;</a></h2>
<!-- (install)= -->

<h3 id="minimal-installation">Minimal installation<a class="headerlink" href="#minimal-installation" title="Permanent link">&para;</a></h3>
<!-- (minimal-install)= -->

<p>Base <code>onetl</code> package contains:</p>
<ul>
<li><code>DBReader</code>, <code>DBWriter</code> and related classes</li>
<li><code>FileDownloader</code>, <code>FileUploader</code>, <code>FileMover</code> and related classes, like file filters &amp; limits</li>
<li><code>FileDFReader</code>, <code>FileDFWriter</code> and related classes, like file formats</li>
<li>Read Strategies &amp; HWM classes</li>
<li>Plugins support</li>
</ul>
<p>It can be installed via:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>onetl
</code></pre></div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This method does NOT include any connections.</p>
<p>This method is recommended for use in third-party libraries which require for <code>onetl</code> to be installed,
but do not use its connection classes.</p>
</div>
<h3 id="with-db-and-filedf-connections">With DB and FileDF connections<a class="headerlink" href="#with-db-and-filedf-connections" title="Permanent link">&para;</a></h3>
<!-- (spark-install)= -->

<p>All DB connection classes (<code>Clickhouse</code>, <code>Greenplum</code>, <code>Hive</code> and others)
and all FileDF connection classes (<code>SparkHDFS</code>, <code>SparkLocalFS</code>, <code>SparkS3</code>)
require Spark to be installed.</p>
<!-- (java-install)= -->

<p>Firstly, you should install JDK. The exact installation instruction depends on your OS, here are some examples:</p>
<div class="highlight"><pre><span></span><code>yum<span class="w"> </span>install<span class="w"> </span>java-1.8.0-openjdk-devel<span class="w">  </span><span class="c1"># CentOS 7 | Spark 2</span>
dnf<span class="w"> </span>install<span class="w"> </span>java-11-openjdk-devel<span class="w">  </span><span class="c1"># CentOS 8 | Spark 3</span>
apt-get<span class="w"> </span>install<span class="w"> </span>openjdk-11-jdk<span class="w">  </span><span class="c1"># Debian-based | Spark 3</span>
</code></pre></div>
<!-- (spark-compatibility-matrix)= -->

<h4 id="compatibility-matrix">Compatibility matrix<a class="headerlink" href="#compatibility-matrix" title="Permanent link">&para;</a></h4>
<table>
<thead>
<tr>
<th>Spark</th>
<th>Python</th>
<th>Java</th>
<th>Scala</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://spark.apache.org/docs/2.3.1/#downloading">2.3.x</a></td>
<td>3.7 only</td>
<td>8 only</td>
<td>2.11</td>
</tr>
<tr>
<td><a href="https://spark.apache.org/docs/2.4.8/#downloading">2.4.x</a></td>
<td>3.7 only</td>
<td>8 only</td>
<td>2.11</td>
</tr>
<tr>
<td><a href="https://spark.apache.org/docs/3.2.4/#downloading">3.2.x</a></td>
<td>3.7 - 3.10</td>
<td>8u201 - 11</td>
<td>2.12</td>
</tr>
<tr>
<td><a href="https://spark.apache.org/docs/3.3.4/#downloading">3.3.x</a></td>
<td>3.7 - 3.12</td>
<td>8u201 - 17</td>
<td>2.12</td>
</tr>
<tr>
<td><a href="https://spark.apache.org/docs/3.4.4/#downloading">3.4.x</a></td>
<td>3.7 - 3.12</td>
<td>8u362 - 20</td>
<td>2.12</td>
</tr>
<tr>
<td><a href="https://spark.apache.org/docs/3.5.5/#downloading">3.5.x</a></td>
<td>3.8 - 3.13</td>
<td>8u371 - 20</td>
<td>2.12</td>
</tr>
</tbody>
</table>
<!-- (pyspark-install)= -->

<p>Then you should install PySpark via passing <code>spark</code> to <code>extras</code>:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>onetl<span class="o">[</span>spark<span class="o">]</span><span class="w">  </span><span class="c1"># install latest PySpark</span>
</code></pre></div>
<p>or install PySpark explicitly:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>onetl<span class="w"> </span><span class="nv">pyspark</span><span class="o">==</span><span class="m">3</span>.5.5<span class="w">  </span><span class="c1"># install a specific PySpark version</span>
</code></pre></div>
<p>or inject PySpark to <code>sys.path</code> in some other way BEFORE creating a class instance.
<strong>Otherwise connection object cannot be created.</strong></p>
<h3 id="with-file-connections">With File connections<a class="headerlink" href="#with-file-connections" title="Permanent link">&para;</a></h3>
<!-- (files-install)= -->

<p>All File (but not <em>FileDF</em>) connection classes (<code>FTP</code>, <code>SFTP</code>, <code>HDFS</code> and so on) requires specific Python clients to be installed.</p>
<p>Each client can be installed explicitly by passing connector name (in lowercase) to <code>extras</code>:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>onetl<span class="o">[</span>ftp<span class="o">]</span><span class="w">  </span><span class="c1"># specific connector</span>
pip<span class="w"> </span>install<span class="w"> </span>onetl<span class="o">[</span>ftp,ftps,sftp,hdfs,s3,webdav,samba<span class="o">]</span><span class="w">  </span><span class="c1"># multiple connectors</span>
</code></pre></div>
<p>To install all file connectors at once you can pass <code>files</code> to <code>extras</code>:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>onetl<span class="o">[</span>files<span class="o">]</span>
</code></pre></div>
<p><strong>Otherwise class import will fail.</strong></p>
<h3 id="with-kerberos-support">With Kerberos support<a class="headerlink" href="#with-kerberos-support" title="Permanent link">&para;</a></h3>
<!-- (kerberos-install)= -->

<p>Most of Hadoop instances set up with Kerberos support,
so some connections require additional setup to work properly.</p>
<ul>
<li><code>HDFS</code>
  Uses <a href="https://pypi.org/project/requests-kerberos/">requests-kerberos</a> and
  <a href="https://pypi.org/project/gssapi/">GSSApi</a> for authentication.
  It also uses <code>kinit</code> executable to generate Kerberos ticket.</li>
<li><code>Hive</code> and <code>SparkHDFS</code>
  require Kerberos ticket to exist before creating Spark session.</li>
</ul>
<p>So you need to install OS packages with:</p>
<ul>
<li><code>krb5</code> libs</li>
<li>Headers for <code>krb5</code></li>
<li><code>gcc</code> or other compiler for C sources</li>
</ul>
<p>The exact installation instruction depends on your OS, here are some examples:</p>
<div class="highlight"><pre><span></span><code>apt<span class="w"> </span>install<span class="w"> </span>libkrb5-dev<span class="w"> </span>krb5-user<span class="w"> </span>gcc<span class="w">  </span><span class="c1"># Debian-based</span>
dnf<span class="w"> </span>install<span class="w"> </span>krb5-devel<span class="w"> </span>krb5-libs<span class="w"> </span>krb5-workstation<span class="w"> </span>gcc<span class="w">  </span><span class="c1"># CentOS, OracleLinux</span>
</code></pre></div>
<p>Also you should pass <code>kerberos</code> to <code>extras</code> to install required Python packages:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>onetl<span class="o">[</span>kerberos<span class="o">]</span>
</code></pre></div>
<h3 id="full-bundle">Full bundle<a class="headerlink" href="#full-bundle" title="Permanent link">&para;</a></h3>
<!-- (full-bundle-1)= -->

<p>To install all connectors and dependencies, you can pass <code>all</code> into <code>extras</code>:</p>
<div class="highlight"><pre><span></span><code>pip<span class="w"> </span>install<span class="w"> </span>onetl<span class="o">[</span>all<span class="o">]</span>

<span class="c1"># this is just the same as</span>
pip<span class="w"> </span>install<span class="w"> </span>onetl<span class="o">[</span>spark,files,kerberos<span class="o">]</span>
</code></pre></div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This method consumes a lot of disk space, and requires for Java &amp; Kerberos libraries to be installed into your OS.</p>
</div>
<!-- (quick-start)= -->

<h2 id="quick-start">Quick start<a class="headerlink" href="#quick-start" title="Permanent link">&para;</a></h2>
<h3 id="mssql-hive">MSSQL → Hive<a class="headerlink" href="#mssql-hive" title="Permanent link">&para;</a></h3>
<p>Read data from MSSQL, transform &amp; write to Hive.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># install onETL and PySpark</span>
pip<span class="w"> </span>install<span class="w"> </span>onetl<span class="o">[</span>spark<span class="o">]</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># Import pyspark to initialize the SparkSession</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql</span><span class="w"> </span><span class="kn">import</span> <span class="n">SparkSession</span>

<span class="c1"># import function to setup onETL logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.log</span><span class="w"> </span><span class="kn">import</span> <span class="n">setup_logging</span>

<span class="c1"># Import required connections</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.connection</span><span class="w"> </span><span class="kn">import</span> <span class="n">MSSQL</span><span class="p">,</span> <span class="n">Hive</span>

<span class="c1"># Import onETL classes to read &amp; write data</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.db</span><span class="w"> </span><span class="kn">import</span> <span class="n">DBReader</span><span class="p">,</span> <span class="n">DBWriter</span>

<span class="c1"># change logging level to INFO, and set up default logging format and handler</span>
<span class="n">setup_logging</span><span class="p">()</span>

<span class="c1"># Initialize new SparkSession with MSSQL driver loaded</span>
<span class="n">maven_packages</span> <span class="o">=</span> <span class="n">MSSQL</span><span class="o">.</span><span class="n">get_packages</span><span class="p">()</span>
<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;spark_app_onetl_demo&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.jars.packages&quot;</span><span class="p">,</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">maven_packages</span><span class="p">))</span>
    <span class="o">.</span><span class="n">enableHiveSupport</span><span class="p">()</span>  <span class="c1"># for Hive</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># Initialize MSSQL connection and check if database is accessible</span>
<span class="n">mssql</span> <span class="o">=</span> <span class="n">MSSQL</span><span class="p">(</span>
    <span class="n">host</span><span class="o">=</span><span class="s2">&quot;mssqldb.demo.com&quot;</span><span class="p">,</span>
    <span class="n">user</span><span class="o">=</span><span class="s2">&quot;onetl&quot;</span><span class="p">,</span>
    <span class="n">password</span><span class="o">=</span><span class="s2">&quot;onetl&quot;</span><span class="p">,</span>
    <span class="n">database</span><span class="o">=</span><span class="s2">&quot;Telecom&quot;</span><span class="p">,</span>
    <span class="n">spark</span><span class="o">=</span><span class="n">spark</span><span class="p">,</span>
    <span class="c1"># These options are passed to MSSQL JDBC Driver:</span>
    <span class="n">extra</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;applicationIntent&quot;</span><span class="p">:</span> <span class="s2">&quot;ReadOnly&quot;</span><span class="p">},</span>
<span class="p">)</span><span class="o">.</span><span class="n">check</span><span class="p">()</span>

<span class="c1"># &gt;&gt;&gt; INFO:|MSSQL| Connection is available</span>

<span class="c1"># Initialize DBReader</span>
<span class="n">reader</span> <span class="o">=</span> <span class="n">DBReader</span><span class="p">(</span>
    <span class="n">connection</span><span class="o">=</span><span class="n">mssql</span><span class="p">,</span>
    <span class="n">source</span><span class="o">=</span><span class="s2">&quot;dbo.demo_table&quot;</span><span class="p">,</span>
    <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;on&quot;</span><span class="p">,</span> <span class="s2">&quot;etl&quot;</span><span class="p">],</span>
    <span class="c1"># Set some MSSQL read options:</span>
    <span class="n">options</span><span class="o">=</span><span class="n">MSSQL</span><span class="o">.</span><span class="n">ReadOptions</span><span class="p">(</span><span class="n">fetchsize</span><span class="o">=</span><span class="mi">10000</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># checks that there is data in the table, otherwise raises exception</span>
<span class="n">reader</span><span class="o">.</span><span class="n">raise_if_no_data</span><span class="p">()</span>

<span class="c1"># Read data to DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="c1"># root</span>
<span class="c1">#  |-- id: integer (nullable = true)</span>
<span class="c1">#  |-- phone_number: string (nullable = true)</span>
<span class="c1">#  |-- region: string (nullable = true)</span>
<span class="c1">#  |-- birth_date: date (nullable = true)</span>
<span class="c1">#  |-- registered_at: timestamp (nullable = true)</span>
<span class="c1">#  |-- account_balance: double (nullable = true)</span>

<span class="c1"># Apply any PySpark transformations</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">lit</span>

<span class="n">df_to_write</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;engine&quot;</span><span class="p">,</span> <span class="n">lit</span><span class="p">(</span><span class="s2">&quot;onetl&quot;</span><span class="p">))</span>
<span class="n">df_to_write</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="c1"># root</span>
<span class="c1">#  |-- id: integer (nullable = true)</span>
<span class="c1">#  |-- phone_number: string (nullable = true)</span>
<span class="c1">#  |-- region: string (nullable = true)</span>
<span class="c1">#  |-- birth_date: date (nullable = true)</span>
<span class="c1">#  |-- registered_at: timestamp (nullable = true)</span>
<span class="c1">#  |-- account_balance: double (nullable = true)</span>
<span class="c1">#  |-- engine: string (nullable = false)</span>

<span class="c1"># Initialize Hive connection</span>
<span class="n">hive</span> <span class="o">=</span> <span class="n">Hive</span><span class="p">(</span><span class="n">cluster</span><span class="o">=</span><span class="s2">&quot;rnd-dwh&quot;</span><span class="p">,</span> <span class="n">spark</span><span class="o">=</span><span class="n">spark</span><span class="p">)</span>

<span class="c1"># Initialize DBWriter</span>
<span class="n">db_writer</span> <span class="o">=</span> <span class="n">DBWriter</span><span class="p">(</span>
    <span class="n">connection</span><span class="o">=</span><span class="n">hive</span><span class="p">,</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;dl_sb.demo_table&quot;</span><span class="p">,</span>
    <span class="c1"># Set some Hive write options:</span>
    <span class="n">options</span><span class="o">=</span><span class="n">Hive</span><span class="o">.</span><span class="n">WriteOptions</span><span class="p">(</span><span class="n">if_exists</span><span class="o">=</span><span class="s2">&quot;replace_entire_table&quot;</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Write data from DataFrame to Hive</span>
<span class="n">db_writer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">df_to_write</span><span class="p">)</span>

<span class="c1"># Success!</span>
</code></pre></div>
<h3 id="sftp-hdfs">SFTP → HDFS<a class="headerlink" href="#sftp-hdfs" title="Permanent link">&para;</a></h3>
<p>Download files from SFTP &amp; upload them to HDFS.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># install onETL with SFTP and HDFS clients, and Kerberos support</span>
pip<span class="w"> </span>install<span class="w"> </span>onetl<span class="o">[</span>hdfs,sftp,kerberos<span class="o">]</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># import function to setup onETL logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.log</span><span class="w"> </span><span class="kn">import</span> <span class="n">setup_logging</span>

<span class="c1"># Import required connections</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.connection</span><span class="w"> </span><span class="kn">import</span> <span class="n">SFTP</span><span class="p">,</span> <span class="n">HDFS</span>

<span class="c1"># Import onETL classes to download &amp; upload files</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.file</span><span class="w"> </span><span class="kn">import</span> <span class="n">FileDownloader</span><span class="p">,</span> <span class="n">FileUploader</span>

<span class="c1"># import filter &amp; limit classes</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.file.filter</span><span class="w"> </span><span class="kn">import</span> <span class="n">Glob</span><span class="p">,</span> <span class="n">ExcludeDir</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.file.limit</span><span class="w"> </span><span class="kn">import</span> <span class="n">MaxFilesCount</span>

<span class="c1"># change logging level to INFO, and set up default logging format and handler</span>
<span class="n">setup_logging</span><span class="p">()</span>

<span class="c1"># Initialize SFTP connection and check it</span>
<span class="n">sftp</span> <span class="o">=</span> <span class="n">SFTP</span><span class="p">(</span>
    <span class="n">host</span><span class="o">=</span><span class="s2">&quot;sftp.test.com&quot;</span><span class="p">,</span>
    <span class="n">user</span><span class="o">=</span><span class="s2">&quot;someuser&quot;</span><span class="p">,</span>
    <span class="n">password</span><span class="o">=</span><span class="s2">&quot;somepassword&quot;</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">check</span><span class="p">()</span>

<span class="c1"># &gt;&gt;&gt; INFO:|SFTP| Connection is available</span>

<span class="c1"># Initialize downloader</span>
<span class="n">file_downloader</span> <span class="o">=</span> <span class="n">FileDownloader</span><span class="p">(</span>
    <span class="n">connection</span><span class="o">=</span><span class="n">sftp</span><span class="p">,</span>
    <span class="n">source_path</span><span class="o">=</span><span class="s2">&quot;/remote/tests/Report&quot;</span><span class="p">,</span>  <span class="c1"># path on SFTP</span>
    <span class="n">local_path</span><span class="o">=</span><span class="s2">&quot;/local/onetl/Report&quot;</span><span class="p">,</span>  <span class="c1"># local fs path</span>
    <span class="n">filters</span><span class="o">=</span><span class="p">[</span>
        <span class="c1"># download only files matching the glob</span>
        <span class="n">Glob</span><span class="p">(</span><span class="s2">&quot;*.csv&quot;</span><span class="p">),</span>
        <span class="c1"># exclude files from this directory</span>
        <span class="n">ExcludeDir</span><span class="p">(</span><span class="s2">&quot;/remote/tests/Report/exclude_dir/&quot;</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">limits</span><span class="o">=</span><span class="p">[</span>
        <span class="c1"># download max 1000 files per run</span>
        <span class="n">MaxFilesCount</span><span class="p">(</span><span class="mi">1000</span><span class="p">),</span>
    <span class="p">],</span>
    <span class="n">options</span><span class="o">=</span><span class="n">FileDownloader</span><span class="o">.</span><span class="n">Options</span><span class="p">(</span>
        <span class="c1"># delete files from SFTP after successful download</span>
        <span class="n">delete_source</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="c1"># mark file as failed if it already exist in local_path</span>
        <span class="n">if_exists</span><span class="o">=</span><span class="s2">&quot;error&quot;</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Download files to local filesystem</span>
<span class="n">download_result</span> <span class="o">=</span> <span class="n">downloader</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

<span class="c1"># Method run returns a DownloadResult object,</span>
<span class="c1"># which contains collection of downloaded files, divided to 4 categories</span>
<span class="n">download_result</span>

<span class="c1">#  DownloadResult(</span>
<span class="c1">#      successful=[</span>
<span class="c1">#          LocalPath(&#39;/local/onetl/Report/file_1.json&#39;),</span>
<span class="c1">#          LocalPath(&#39;/local/onetl/Report/file_2.json&#39;),</span>
<span class="c1">#      ],</span>
<span class="c1">#      failed=[FailedRemoteFile(&#39;/remote/onetl/Report/file_3.json&#39;)],</span>
<span class="c1">#      ignored=[RemoteFile(&#39;/remote/onetl/Report/file_4.json&#39;)],</span>
<span class="c1">#      missing=[],</span>
<span class="c1">#  )</span>

<span class="c1"># Raise exception if there are failed files, or there were no files in the remote filesystem</span>
<span class="n">download_result</span><span class="o">.</span><span class="n">raise_if_failed</span><span class="p">()</span> <span class="ow">or</span> <span class="n">download_result</span><span class="o">.</span><span class="n">raise_if_empty</span><span class="p">()</span>

<span class="c1"># Do any kind of magic with files: rename files, remove header for csv files, ...</span>
<span class="n">renamed_files</span> <span class="o">=</span> <span class="n">my_rename_function</span><span class="p">(</span><span class="n">download_result</span><span class="o">.</span><span class="n">success</span><span class="p">)</span>

<span class="c1"># function removed &quot;_&quot; from file names</span>
<span class="c1"># [</span>
<span class="c1">#    LocalPath(&#39;/home/onetl/Report/file1.json&#39;),</span>
<span class="c1">#    LocalPath(&#39;/home/onetl/Report/file2.json&#39;),</span>
<span class="c1"># ]</span>

<span class="c1"># Initialize HDFS connection</span>
<span class="n">hdfs</span> <span class="o">=</span> <span class="n">HDFS</span><span class="p">(</span>
    <span class="n">host</span><span class="o">=</span><span class="s2">&quot;my.name.node&quot;</span><span class="p">,</span>
    <span class="n">user</span><span class="o">=</span><span class="s2">&quot;someuser&quot;</span><span class="p">,</span>
    <span class="n">password</span><span class="o">=</span><span class="s2">&quot;somepassword&quot;</span><span class="p">,</span>  <span class="c1"># or keytab</span>
<span class="p">)</span>

<span class="c1"># Initialize uploader</span>
<span class="n">file_uploader</span> <span class="o">=</span> <span class="n">FileUploader</span><span class="p">(</span>
    <span class="n">connection</span><span class="o">=</span><span class="n">hdfs</span><span class="p">,</span>
    <span class="n">target_path</span><span class="o">=</span><span class="s2">&quot;/user/onetl/Report/&quot;</span><span class="p">,</span>  <span class="c1"># hdfs path</span>
<span class="p">)</span>

<span class="c1"># Upload files from local fs to HDFS</span>
<span class="n">upload_result</span> <span class="o">=</span> <span class="n">file_uploader</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">renamed_files</span><span class="p">)</span>

<span class="c1"># Method run returns a UploadResult object,</span>
<span class="c1"># which contains collection of uploaded files, divided to 4 categories</span>
<span class="n">upload_result</span>

<span class="c1">#  UploadResult(</span>
<span class="c1">#      successful=[RemoteFile(&#39;/user/onetl/Report/file1.json&#39;)],</span>
<span class="c1">#      failed=[FailedLocalFile(&#39;/local/onetl/Report/file2.json&#39;)],</span>
<span class="c1">#      ignored=[],</span>
<span class="c1">#      missing=[],</span>
<span class="c1">#  )</span>

<span class="c1"># Raise exception if there are failed files, or there were no files in the local filesystem, or some input file is missing</span>
<span class="n">upload_result</span><span class="o">.</span><span class="n">raise_if_failed</span><span class="p">()</span> <span class="ow">or</span> <span class="n">upload_result</span><span class="o">.</span><span class="n">raise_if_empty</span><span class="p">()</span> <span class="ow">or</span> <span class="n">upload_result</span><span class="o">.</span><span class="n">raise_if_missing</span><span class="p">()</span>

<span class="c1"># Success!</span>
</code></pre></div>
<h3 id="s3-postgres">S3 → Postgres<a class="headerlink" href="#s3-postgres" title="Permanent link">&para;</a></h3>
<p>Read files directly from S3 path, convert them to dataframe, transform it and then write to a database.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># install onETL and PySpark</span>
pip<span class="w"> </span>install<span class="w"> </span>onetl<span class="o">[</span>spark<span class="o">]</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># Import pyspark to initialize the SparkSession</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql</span><span class="w"> </span><span class="kn">import</span> <span class="n">SparkSession</span>

<span class="c1"># import function to setup onETL logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.log</span><span class="w"> </span><span class="kn">import</span> <span class="n">setup_logging</span>

<span class="c1"># Import required connections</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.connection</span><span class="w"> </span><span class="kn">import</span> <span class="n">Postgres</span><span class="p">,</span> <span class="n">SparkS3</span>

<span class="c1"># Import onETL classes to read files</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.file</span><span class="w"> </span><span class="kn">import</span> <span class="n">FileDFReader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.file.format</span><span class="w"> </span><span class="kn">import</span> <span class="n">CSV</span>

<span class="c1"># Import onETL classes to write data</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">onetl.db</span><span class="w"> </span><span class="kn">import</span> <span class="n">DBWriter</span>

<span class="c1"># change logging level to INFO, and set up default logging format and handler</span>
<span class="n">setup_logging</span><span class="p">()</span>

<span class="c1"># Initialize new SparkSession with Hadoop AWS libraries and Postgres driver loaded</span>
<span class="n">maven_packages</span> <span class="o">=</span> <span class="n">SparkS3</span><span class="o">.</span><span class="n">get_packages</span><span class="p">(</span><span class="n">spark_version</span><span class="o">=</span><span class="s2">&quot;3.5.5&quot;</span><span class="p">)</span> <span class="o">|</span> <span class="n">Postgres</span><span class="o">.</span><span class="n">get_packages</span><span class="p">()</span>
<span class="n">exclude_packages</span> <span class="o">=</span> <span class="n">SparkS3</span><span class="o">.</span><span class="n">get_exclude_packages</span><span class="p">()</span>
<span class="n">spark</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">SparkSession</span><span class="o">.</span><span class="n">builder</span><span class="o">.</span><span class="n">appName</span><span class="p">(</span><span class="s2">&quot;spark_app_onetl_demo&quot;</span><span class="p">)</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.jars.packages&quot;</span><span class="p">,</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">maven_packages</span><span class="p">))</span>
    <span class="o">.</span><span class="n">config</span><span class="p">(</span><span class="s2">&quot;spark.jars.excludes&quot;</span><span class="p">,</span> <span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">exclude_packages</span><span class="p">))</span>
    <span class="o">.</span><span class="n">getOrCreate</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># Initialize S3 connection and check it</span>
<span class="n">spark_s3</span> <span class="o">=</span> <span class="n">SparkS3</span><span class="p">(</span>
    <span class="n">host</span><span class="o">=</span><span class="s2">&quot;s3.test.com&quot;</span><span class="p">,</span>
    <span class="n">protocol</span><span class="o">=</span><span class="s2">&quot;https&quot;</span><span class="p">,</span>
    <span class="n">bucket</span><span class="o">=</span><span class="s2">&quot;my-bucket&quot;</span><span class="p">,</span>
    <span class="n">access_key</span><span class="o">=</span><span class="s2">&quot;somekey&quot;</span><span class="p">,</span>
    <span class="n">secret_key</span><span class="o">=</span><span class="s2">&quot;somesecret&quot;</span><span class="p">,</span>
    <span class="c1"># Access bucket as s3.test.com/my-bucket</span>
    <span class="n">extra</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;path.style.access&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">},</span>
    <span class="n">spark</span><span class="o">=</span><span class="n">spark</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">check</span><span class="p">()</span>

<span class="c1"># &gt;&gt;&gt; INFO:|SparkS3| Connection is available</span>

<span class="c1"># Describe file format and parsing options</span>
<span class="n">csv</span> <span class="o">=</span> <span class="n">CSV</span><span class="p">(</span>
    <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;;&quot;</span><span class="p">,</span>
    <span class="n">header</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Describe DataFrame schema of files</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.types</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">DateType</span><span class="p">,</span>
    <span class="n">DoubleType</span><span class="p">,</span>
    <span class="n">IntegerType</span><span class="p">,</span>
    <span class="n">StringType</span><span class="p">,</span>
    <span class="n">StructField</span><span class="p">,</span>
    <span class="n">StructType</span><span class="p">,</span>
    <span class="n">TimestampType</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">df_schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="n">IntegerType</span><span class="p">()),</span>
        <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;phone_number&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()),</span>
        <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;region&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">()),</span>
        <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;birth_date&quot;</span><span class="p">,</span> <span class="n">DateType</span><span class="p">()),</span>
        <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;registered_at&quot;</span><span class="p">,</span> <span class="n">TimestampType</span><span class="p">()),</span>
        <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;account_balance&quot;</span><span class="p">,</span> <span class="n">DoubleType</span><span class="p">()),</span>
    <span class="p">],</span>
<span class="p">)</span>

<span class="c1"># Initialize file df reader</span>
<span class="n">reader</span> <span class="o">=</span> <span class="n">FileDFReader</span><span class="p">(</span>
    <span class="n">connection</span><span class="o">=</span><span class="n">spark_s3</span><span class="p">,</span>
    <span class="n">source_path</span><span class="o">=</span><span class="s2">&quot;/remote/tests/Report&quot;</span><span class="p">,</span>  <span class="c1"># path on S3 there *.csv files are located</span>
    <span class="nb">format</span><span class="o">=</span><span class="n">csv</span><span class="p">,</span>  <span class="c1"># file format with specific parsing options</span>
    <span class="n">df_schema</span><span class="o">=</span><span class="n">df_schema</span><span class="p">,</span>  <span class="c1"># columns &amp; types</span>
<span class="p">)</span>

<span class="c1"># Read files directly from S3 as Spark DataFrame</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">reader</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>

<span class="c1"># Check that DataFrame schema is same as expected</span>
<span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="c1"># root</span>
<span class="c1">#  |-- id: integer (nullable = true)</span>
<span class="c1">#  |-- phone_number: string (nullable = true)</span>
<span class="c1">#  |-- region: string (nullable = true)</span>
<span class="c1">#  |-- birth_date: date (nullable = true)</span>
<span class="c1">#  |-- registered_at: timestamp (nullable = true)</span>
<span class="c1">#  |-- account_balance: double (nullable = true)</span>

<span class="c1"># Apply any PySpark transformations</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pyspark.sql.functions</span><span class="w"> </span><span class="kn">import</span> <span class="n">lit</span>

<span class="n">df_to_write</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;engine&quot;</span><span class="p">,</span> <span class="n">lit</span><span class="p">(</span><span class="s2">&quot;onetl&quot;</span><span class="p">))</span>
<span class="n">df_to_write</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
<span class="c1"># root</span>
<span class="c1">#  |-- id: integer (nullable = true)</span>
<span class="c1">#  |-- phone_number: string (nullable = true)</span>
<span class="c1">#  |-- region: string (nullable = true)</span>
<span class="c1">#  |-- birth_date: date (nullable = true)</span>
<span class="c1">#  |-- registered_at: timestamp (nullable = true)</span>
<span class="c1">#  |-- account_balance: double (nullable = true)</span>
<span class="c1">#  |-- engine: string (nullable = false)</span>

<span class="c1"># Initialize Postgres connection</span>
<span class="n">postgres</span> <span class="o">=</span> <span class="n">Postgres</span><span class="p">(</span>
    <span class="n">host</span><span class="o">=</span><span class="s2">&quot;192.169.11.23&quot;</span><span class="p">,</span>
    <span class="n">user</span><span class="o">=</span><span class="s2">&quot;onetl&quot;</span><span class="p">,</span>
    <span class="n">password</span><span class="o">=</span><span class="s2">&quot;somepassword&quot;</span><span class="p">,</span>
    <span class="n">database</span><span class="o">=</span><span class="s2">&quot;mydb&quot;</span><span class="p">,</span>
    <span class="n">spark</span><span class="o">=</span><span class="n">spark</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Initialize DBWriter</span>
<span class="n">db_writer</span> <span class="o">=</span> <span class="n">DBWriter</span><span class="p">(</span>
    <span class="n">connection</span><span class="o">=</span><span class="n">postgres</span><span class="p">,</span>
    <span class="c1"># write to specific table</span>
    <span class="n">target</span><span class="o">=</span><span class="s2">&quot;public.my_table&quot;</span><span class="p">,</span>
    <span class="c1"># with some writing options</span>
    <span class="n">options</span><span class="o">=</span><span class="n">Postgres</span><span class="o">.</span><span class="n">WriteOptions</span><span class="p">(</span><span class="n">if_exists</span><span class="o">=</span><span class="s2">&quot;append&quot;</span><span class="p">),</span>
<span class="p">)</span>

<span class="c1"># Write DataFrame to Postgres table</span>
<span class="n">db_writer</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">df_to_write</span><span class="p">)</span>

<span class="c1"># Success!</span>
</code></pre></div>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.indexes", "content.tabs.link", "content.code.copy", "content.code.select"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="../assets/mkdocs_puml/puml.js"></script>
      
        <script src="https://unpkg.com/@panzoom/panzoom@4.5.1/dist/panzoom.min.js"></script>
      
        <script src="../assets/mkdocs_puml/interaction.js"></script>
      
    
  </body>
</html>
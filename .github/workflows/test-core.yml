name: Tests for core
on:
  workflow_call:
    inputs:
      spark-version:
        required: true
        type: string
      java-version:
        required: true
        type: string
      python-version:
        required: true
        type: string
      os:
        required: false
        type: string
        default: ubuntu-latest

jobs:
  test-core:
    name: Run core tests (spark=${{ inputs.spark-version }}, java=${{ inputs.java-version }}, python=${{ inputs.python-version }}, os=${{ inputs.os }})
    runs-on: ${{ inputs.os }}

    steps:
    - name: Checkout code
      uses: actions/checkout@v3

    - name: Set up Python ${{ inputs.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ inputs.python-version }}

    - name: Set up Java ${{ inputs.java-version }}
      uses: actions/setup-java@v3
      with:
        distribution: temurin
        java-version: ${{ inputs.java-version }}

    - name: Cache pip
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-python-${{ inputs.python-version }}-spark-${{ inputs.spark-version }}-tests-core-${{ hashFiles('requirements/core.txt', 'requirements/tests/base.txt', 'requirements/tests/spark*.txt') }}
        restore-keys: |
          ${{ runner.os }}-python-${{ inputs.python-version }}-spark-${{ inputs.spark-version }}-tests-core-${{ hashFiles('requirements/core.txt', 'requirements/tests/base.txt', 'requirements/tests/spark*.txt') }}
          ${{ runner.os }}-python-${{ inputs.python-version }}-spark-${{ inputs.spark-version }}-tests-core-

    - name: Upgrade pip
      run: python -m pip install --upgrade pip setuptools wheel

    - name: Install dependencies
      run: |
        pip install -I \
          -r requirements/core.txt \
          -r requirements/tests/base.txt \
          -r requirements/tests/spark-${{ inputs.spark-version }}.txt

    - name: Run tests
      run: |
        ./run_tests.sh -m 'not connection'

    - name: Upload coverage results
      uses: actions/upload-artifact@v3
      with:
        name: core-spark-${{ inputs.spark-version }}-python-${{ inputs.python-version }}-os-${{ inputs.os }}
        path: reports/*

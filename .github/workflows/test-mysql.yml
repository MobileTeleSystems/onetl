name: Tests for MySQL
on:
  workflow_call:
    inputs:
      mysql-version:
        required: true
        type: string
      spark-version:
        required: true
        type: string
      java-version:
        required: true
        type: string
      python-version:
        required: true
        type: string
      os:
        required: true
        type: string
      with-cache:
        required: false
        type: boolean
        default: true

jobs:
  test-mysql:
    name: Run MySQL tests (server=${{ inputs.mysql-version }}, spark=${{ inputs.spark-version }}, java=${{ inputs.java-version }}, python=${{ inputs.python-version }}, os=${{ inputs.os }})
    runs-on: ${{ inputs.os }}
    services:
      mysql:
        image: mysql:${{ inputs.mysql-version }}
        env:
          TZ: UTC
          MYSQL_ROOT_PASSWORD: ohbuz9Eochaj9saibooK3thooGa5aesh
          MYSQL_DATABASE: onetl
          MYSQL_USER: onetl
          MYSQL_PASSWORD: ohbuz9Eochaj9saibooK3thooGa5aesh
        ports:
        - 3306:3306

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Java ${{ inputs.java-version }}
      uses: actions/setup-java@v4
      with:
        distribution: temurin
        java-version: ${{ inputs.java-version }}

    - name: Set up Python ${{ inputs.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ inputs.python-version }}

    - name: Cache Ivy
      uses: actions/cache@v4
      if: inputs.with-cache
      with:
        path: ~/.ivy2
        key: ${{ runner.os }}-ivy-${{ inputs.spark-version }}-tests-mysql-${{ hashFiles('onetl/connection/db_connection/*.py', 'onetl/connection/file_df_connection/*.py') }}
        restore-keys: |
          ${{ runner.os }}-ivy-${{ inputs.spark-version }}-tests-mysql-${{ hashFiles('onetl/connection/db_connection/*.py', 'onetl/connection/file_df_connection/*.py') }}
          ${{ runner.os }}-ivy-${{ inputs.spark-version }}-tests-mysql-

    - name: Cache pip
      uses: actions/cache@v4
      if: inputs.with-cache
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-python-${{ inputs.python-version }}-tests-mysql-${{ hashFiles('requirements/core.txt', 'requirements/tests/base.txt', 'requirements/tests/mysql.txt', 'requirements/tests/spark-*.txt') }}
        restore-keys: |
          ${{ runner.os }}-python-${{ inputs.python-version }}-tests-mysql-${{ hashFiles('requirements/core.txt', 'requirements/tests/base.txt', 'requirements/tests/mysql.txt', 'requirements/tests/spark-*.txt') }}
          ${{ runner.os }}-python-${{ inputs.python-version }}-tests-mysql-

    - name: Upgrade pip
      run: python -m pip install --upgrade pip setuptools wheel

    - name: Install dependencies
      run: |
        pip install -I -r requirements/core.txt -r requirements/tests/base.txt -r requirements/tests/mysql.txt -r requirements/tests/spark-${{ inputs.spark-version }}.txt

    - name: Wait for MySQL to be ready
      run: |
        ./docker/wait-for-it.sh -h localhost -p 3306 -t 60

    - name: Run tests
      run: |
        mkdir reports/ || echo "Directory exists"
        sed '/^$/d' ./.env.local | sed '/^#/d' | sed 's/^/export /' > ./env
        source ./env
        ./pytest_runner.sh -m mysql

    - name: Upload coverage results
      uses: actions/upload-artifact@v4
      with:
        name: mysql-${{ inputs.mysql-version }}-spark-${{ inputs.spark-version }}-python-${{ inputs.python-version }}-os-${{ inputs.os }}
        path: reports/*
